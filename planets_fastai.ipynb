{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom pathlib import Path\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#       print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from fastai.vision.all import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import the planets-dataset. A dataframe train_df is constructed from the the csv file containing the file names of images and the labels for each of the images. The labels are multicategory."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = Path('../input/planets-dataset/planet/planet')\n\ntrain_df = pd.read_csv(train_path/'train_classes.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Datablock API from fastai was used to prepare the training data testing data. The Dtablock object was passed to dataloaders object which is an iterable returning the mini batches of traing data and testing data as tuples. Each tuple has a batch of taining data i.e. image and the labe associated with it. The Datablock object also included the methods to transform and augment the training data. The item_tfms method transforms images itemwise using CPU and batch_tfms transforms images in batches using GPU."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_x(r): return train_path/'train-jpg'/(r['image_name']+'.jpg')\ndef get_y(r): return r['tags'].split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                  splitter=RandomSplitter(seed=42),\n                  get_x=get_x,\n                  get_y=get_y,\n                  item_tfms=Resize(224),\n                  batch_tfms=[*aug_transforms(flip_vert=True, max_warp=0),\n                             Normalize.from_stats(*imagenet_stats)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls = dblock.dataloaders(train_df, bs=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls.show_batch(nrows=1, ncols=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The metrics of the model measure the performance of the model in the test data. Fastai by default uses multiclass accuracy for multilabel data. Here the f2 score is also defined to comply with this Kaggle competition rules."},{"metadata":{"trusted":true},"cell_type":"code","source":"f2samples = FBetaMulti(beta=2, average='samples', thresh=0.5)\nmetrics = [partial(accuracy_multi, thresh=0.5), f2samples]\ncbs = MixUp()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, as a baseline model, let's train a resnet34 network. The lr_find() helps to find the optimum learning rate. It returns the learning rate at which loss is minimum (lr_min) and the learning rate at which the loss is decreasing at the fastest rate (lr_steep).   "},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(dls,resnet34, metrics=metrics, cbs=cbs)\nlr_min, lr_steep = learn.lr_find()\nlr_min, lr_steep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fine_tune(1, 3e-2)\nlr_min, lr_steep = learn.lr_find()\nlr_min, lr_steep","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I am trying to get an optimum threshold for the metrics."},{"metadata":{"trusted":true},"cell_type":"code","source":"preds, targets = learn.get_preds()\nxs = torch.linspace(0.1, 0.9, 29)\naccs = [accuracy_multi(preds, targets, thresh=i, sigmoid=False) for i in xs]\nplt.plot(xs,accs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The figure above suggests that the threshhold should be around 0.4."},{"metadata":{"trusted":true},"cell_type":"code","source":"f2samples = FBetaMulti(beta=2, average='samples', thresh=0.4)\nmetrics = [partial(accuracy_multi, thresh=0.4), f2samples]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, lets train the model using fit_one_cycle() method of the learner. This method updates the weights of last layer of the pretrained resnet34 model and trains it predict the images in current dataset and keeps the earlier layers of the resnet34 model frozen to their pretrained values.\nThen the learn.unfreeze() method is called to unfreeze those earlier layers. The learn.fit_one_cycle() method is called once again to  update t weights of all the layers of the cnn. Here, the lr_max parameter is passed to implement learning descriminitive learning rates. The lower value in the slice will be used for the earliest layer and the learning rates are multiplicatively scaled up to higher rates for later layers."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(3, 5e-4)\nlearn.unfreeze()\nlearn.fit_one_cycle(10, lr_max=slice(1e-5,1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_min, lr_steep = learn.lr_find()\nlr_min, lr_steep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds, targets = learn.get_preds()\nxs = torch.linspace(0.1, 0.9, 29)\naccs = [accuracy_multi(preds, targets, thresh=i, sigmoid=False) for i in xs]\nplt.plot(xs,accs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f2samples = FBetaMulti(beta=2, average='samples', thresh=0.5)\nmetrics = [partial(accuracy_multi, thresh=0.5), f2samples]\nlearn.fine_tune(5, base_lr=1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = Path('../input/planets-dataset/planet/planet/test-jpg')\nadd_path = Path('../input/planets-dataset/test-jpg-additional/test-jpg-additional')\n\nsubmiss_df = pd.read_csv(train_path/'sample_submission.csv')\ntest_path = (submiss_df['image_name']+'.jpg').apply(lambda x: test_path/x if x.startswith('test') else add_path/x)\n\ntest_dl = learn.dls.test_dl(test_path)\npredictions = learn.get_preds(dl = test_dl)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predlist = [' '.join (learn.dls.vocab[i]) for i in (predictions[0]>0.5)]\npredlist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submiss_df['tags'] = predlist\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_path = Path('../kaggle/working')\nsubmiss_df.to_csv(out_path/'amazon_resnet34.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from fastai.callback.fp16 import *\n\n#learn = cnn_learner(dls, resnet50, metrics=metrics).to_fp16()\n#lr_min, lr_steep = learn.lr_find()\n#lr_min, lr_steep\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}